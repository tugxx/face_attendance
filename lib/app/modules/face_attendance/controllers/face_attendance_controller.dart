import 'dart:io';
import 'package:camera/camera.dart';
import 'package:flutter/material.dart';
import 'package:get/get.dart';
import 'package:image_picker/image_picker.dart';
import 'package:google_mlkit_face_detection/google_mlkit_face_detection.dart';
import 'package:image/image.dart' as img;
import 'package:permission_handler/permission_handler.dart';
import '../../../core/utils/camera_utils.dart';
import '../../../core/services/ai_service.dart';
import '../../../core/utils/image_converter.dart';

class FaceAttendanceController extends GetxController {
  CameraController? cameraController;
  final FaceRecognitionService _aiService =
      FaceRecognitionService(); // Instance AI

  var isInitialized = false.obs; // C·ªù b√°o hi·ªáu Camera ƒë√£ b·∫≠t ch∆∞a.
  var recognizedName = "Unknown".obs;
  var isProcessing = false
      .obs; // C√°i "kh√≥a" (Lock/Semaphore) ƒë·ªÉ ngƒÉn kh√¥ng cho x·ª≠ l√Ω qu√° nhi·ªÅu frame c√πng l√∫c (tr√°nh tr√†n RAM).
  var errorMsg = "".obs;

  String _lastRecognizedName = "";
  DateTime _lastDetectionTime = DateTime.now().subtract(
    const Duration(seconds: 10),
  );

  late FaceDetector _faceDetector;
  var isBusy = false;
  var detectedFaces = <Face>[].obs;
  CameraDescription? _currentCamera;

  img.Image? convertedImageTemp;
  Face? faceTemp;

  @override
  void onInit() async {
    super.onInit();
    await _aiService.initialize();

    // 2. C·∫•u h√¨nh ML Kit
    _faceDetector = FaceDetector(
      options: FaceDetectorOptions(
        performanceMode: FaceDetectorMode.accurate, // ∆Øu ti√™n ƒë·ªô ch√≠nh x√°c
        enableContours: false,
        enableLandmarks: false,
      ),
    );

    startCamera(); // T·ª± ƒë·ªông ch·∫°y cam khi controller ƒë∆∞·ª£c t·∫°o
  }

  Future<void> startCamera() async {
    errorMsg.value = "";
    var status = await Permission.camera.request(); // Xin quy·ªÅn Camera
    if (!status.isGranted) {
      errorMsg.value = "Vui l√≤ng c·∫•p quy·ªÅn Camera";
      return;
    }

    final cameras = await availableCameras();
    if (cameras.isEmpty) {
      errorMsg.value = "Kh√¥ng t√¨m th·∫•y Camera";
      return;
    }

    _currentCamera = cameras.firstWhere(
      (c) => c.lensDirection == CameraLensDirection.front,
      orElse: () => cameras.first,
    ); // T√¨m Camera tr∆∞·ªõc

    // await _initializeController(_currentCamera!);
    cameraController = CameraController(
      _currentCamera!,
      ResolutionPreset.medium, // ƒê·ª´ng d√πng High, d√πng Medium cho nh·∫π
      enableAudio: false,
      // T·ª± ƒë·ªông ch·ªçn format chu·∫©n theo OS
      imageFormatGroup: Platform.isAndroid
          ? ImageFormatGroup
                .nv21 // Android
          : ImageFormatGroup.bgra8888, // iOS
    );

    await cameraController!.initialize();
    isInitialized.value = true;

    // B·∫Øt ƒë·∫ßu Stream
    await cameraController!.startImageStream(
      _processFrame,
    ); // ·ªói khi camera b·∫Øt ƒë∆∞·ª£c 1 h√¨nh, n√≥ b·∫Øn ngay v√†o h√†m _processFrame
  }

  // --- LOGIC X·ª¨ L√ù FRAME ---
  void _processFrame(CameraImage image) async {
    // N·∫øu ƒëang b·∫≠n nh·∫≠n di·ªán ai ƒë√≥, v·ª©t b·ªè frame n√†y ngay.
    if (isProcessing.value ||
        DateTime.now().difference(_lastDetectionTime).inMilliseconds < 500) {
      return;
    }

    if (cameraController == null ||
        !cameraController!.value.isStreamingImages) {
      return;
    }

    try {
      // 1. D√πng ML Kit ƒë·ªÉ t√¨m m·∫∑t
      final inputImage = CameraUtils.convertCameraImageToInputImage(
        image,
        _currentCamera!,
      );
      if (inputImage == null) return;

      final faces = await _faceDetector.processImage(inputImage);

      if (isProcessing.value) return;

      // 2. N·∫øu c√≥ m·∫∑t v√† m·∫∑t ƒë·ªß to
      if (faces.isNotEmpty) {
        final face = faces.first;

        // Logic l·ªçc: Ch·ªâ nh·∫≠n di·ªán khi m·∫∑t to > 100px (ng∆∞·ªùi ƒë·ª©ng g·∫ßn)
        if (face.boundingBox.width > 80) {
          // --- B·∫ÆT ƒê·∫¶U PHA X·ª¨ L√ù N·∫∂NG ---
          isProcessing.value = true; // Kh√≥a lu·ªìng l·∫°i

          img.Image? convertedImage = await ImageConverter.convertCameraImage(
            image,
          );

          if (convertedImage == null) {
            debugPrint("‚ö†Ô∏è Convert ·∫£nh th·∫•t b·∫°i -> B·ªè qua frame n√†y");

            _lastDetectionTime = DateTime.now();

            isProcessing.value = false;
            return;
          }

          // Xoay ·∫£nh (Th∆∞·ªùng Android Camera tr∆∞·ªõc b·ªã xoay 270 ƒë·ªô -> c·∫ßn xoay -90 ƒë·ªÉ th·∫≥ng)
          convertedImage = img.copyRotate(convertedImage, angle: -90);

          // final directory = await getTemporaryDirectory();
          // final path =
          //     '${directory.path}/face_capture_${DateTime.now().millisecondsSinceEpoch}.jpg';
          // File faceFile = File(path);
          // await faceFile.writeAsBytes(img.encodeJpg(convertedImage));

          convertedImageTemp = convertedImage;
          faceTemp = face;

          final startTime = DateTime.now();
          String? name = await _aiService.predict(convertedImage, face);
          final aiTime = DateTime.now().difference(startTime).inMilliseconds;

          debugPrint("ü§ñ AI Predict: $name (Time: ${aiTime}ms)");

          if (name != null) {
            if (name != "Unknown" && !name.contains("DB Empty")) {
              recognizedName.value = name;
            }

            if (name == _lastRecognizedName &&
                DateTime.now().difference(_lastDetectionTime).inSeconds < 5) {
              // Tr√πng t√™n v·ªõi l·∫ßn tr∆∞·ªõc v√† trong v√≤ng 5 gi√¢y, b·ªè qua
            } else {
              _lastRecognizedName = name;
              recognizedName.value = name;
              _lastDetectionTime = DateTime.now();

              // UI: Thay v√¨ Snackbar che m√†n h√¨nh, n√™n update Text tr√™n UI
              // Nh∆∞ng n·∫øu d√πng snackbar th√¨ d√πng c√°i n√†y cho ƒë·ª° spam
              if (!Get.isSnackbarOpen) {
                Get.snackbar(
                  "Th√†nh c√¥ng",
                  "Xin ch√†o $name",
                  backgroundColor: Colors.green.withValues(alpha: 0.7),
                  colorText: Colors.white,
                );
              }
            }
          } else {
            recognizedName.value = "Unknown";
          }

          // Delay nh·∫π 1 ch√∫t ƒë·ªÉ user nh√¨n th·∫•y k·∫øt qu·∫£
          await Future.delayed(const Duration(seconds: 2));

          _lastDetectionTime = DateTime.now(); // Reset th·ªùi gian
          isProcessing.value = false; // M·ªû KH√ìA LU·ªíNG
        }
      }
    } catch (e) {
      debugPrint("L·ªói x·ª≠ l√Ω frame: $e");
      isProcessing.value = false;
    }
  }

  // 1. H√†m g·ªçi UI nh·∫≠p t√™n (Gi·ªØ nguy√™n c·ªßa b·∫°n)
  Future<void> registerNewFace() async {
    final ImagePicker picker = ImagePicker();
    final XFile? image = await picker.pickImage(source: ImageSource.gallery);
    if (image == null) return;

    TextEditingController nameController = TextEditingController();
    await Get.defaultDialog(
      title: "Nh·∫≠p t√™n nh√¢n vi√™n",
      content: TextField(
        controller: nameController,
        decoration: const InputDecoration(hintText: "V√≠ d·ª•: Nguyen Van A"),
      ),
      textConfirm: "L∆∞u",
      textCancel: "H·ªßy",
      onConfirm: () async {
        String name = nameController.text.trim();
        if (name.isNotEmpty) {
          Get.back();
          // G·ªçi h√†m x·ª≠ l√Ω file t·ª´ Gallery
          await _processRegistrationGallery(File(image.path), name);
        }
      },
    );
  }

  // 2. H√†m x·ª≠ l√Ω file ·∫£nh t·ª´ Gallery
  Future<void> _processRegistrationGallery(File file, String name) async {
    isProcessing.value = true;
    try {
      debugPrint("‚è≥ ƒêang t·∫°o vector t·ª´ ·∫£nh th∆∞ vi·ªán...");

      // L·∫•y vector t·ª´ file ·∫£nh
      List<double>? embedding = await _aiService.getEmbeddingFromImageFile(
        file,
      );

      if (embedding != null) {
        // L∆∞u vector v√†o DB v·ªõi t√™n ng∆∞·ªùi d√πng
        _aiService.registerUser(name, embedding);

        Get.snackbar(
          "Th√†nh c√¥ng",
          "ƒê√£ th√™m nh√¢n vi√™n: $name",
          backgroundColor: Colors.green,
        );
      } else {
        Get.snackbar(
          "L·ªói",
          "Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t h·ª£p l·ªá trong ·∫£nh",
          backgroundColor: Colors.red,
        );
      }
    } catch (e) {
      Get.snackbar("L·ªói", "C√≥ s·ª± c·ªë: $e");
    } finally {
      isProcessing.value = false;
    }
  }

  // (Optional) N·∫øu b·∫°n mu·ªën l√†m n√∫t "ƒêƒÉng k√Ω ng∆∞·ªùi ƒëang ƒë·ª©ng tr∆∞·ªõc Camera"
  void registerCurrentFace(String name) {
    if (convertedImageTemp != null && faceTemp != null) {
      _aiService.registerFace(convertedImageTemp!, faceTemp!, name);
      Get.snackbar(
        "Th√†nh c√¥ng",
        "ƒê√£ l∆∞u nh√¢n vi√™n: $name",
        backgroundColor: Colors.green,
        colorText: Colors.white,
      );

      // Reset l·∫°i t√™n ƒë·ªÉ l·∫ßn qu√©t t·ªõi n√≥ hi·ªán t√™n m·ªõi lu√¥n
      recognizedName.value = name;
    } else {
      Get.snackbar("L·ªói", "Ch∆∞a nh·∫≠n di·ªán ƒë∆∞·ª£c m·∫∑t ƒë·ªÉ ƒëƒÉng k√Ω");
    }
  }

  @override
  void onClose() {
    _faceDetector.close();
    cameraController?.stopImageStream();
    cameraController?.dispose();
    super.onClose();
  }
}
