import 'dart:io';
// import 'dart:typed_data';
import 'dart:math';
import 'package:camera/camera.dart';
import 'package:flutter/material.dart';
import 'package:get/get.dart';
import 'package:flutter/foundation.dart';
// import 'package:image_picker/image_picker.dart';
import 'package:google_mlkit_face_detection/google_mlkit_face_detection.dart';
import 'package:image/image.dart' as img;
import 'package:permission_handler/permission_handler.dart';
import 'package:path_provider/path_provider.dart';
import 'package:flutter/services.dart';
import 'package:opencv_dart/opencv_dart.dart' as cv;
// import 'package:flutter_image_compress/flutter_image_compress.dart';
// import '../../../core/services/image_converter_ffi.dart';

import '../../../core/utils/camera_utils.dart';
import '../../../core/services/ai_service.dart';
import '../../../core/values/face_progress.dart';
// import '../../../core/utils/image_utils.dart';
// import '../../../core/utils/image_converter.dart';

class FaceAttendanceController extends GetxController {
  CameraController? cameraController;
  final FaceRecognitionService _aiService =
      FaceRecognitionService(); // Instance AI

  var isInitialized = false.obs; // C·ªù b√°o hi·ªáu Camera ƒë√£ b·∫≠t ch∆∞a.
  var recognizedName = "Unknown".obs;
  var isProcessing = false
      .obs; // C√°i "kh√≥a" (Lock/Semaphore) ƒë·ªÉ ngƒÉn kh√¥ng cho x·ª≠ l√Ω qu√° nhi·ªÅu frame c√πng l√∫c (tr√°nh tr√†n RAM).
  var errorMsg = "".obs;

  // String _lastRecognizedName = "";
  DateTime _lastDetectionTime = DateTime.now().subtract(
    const Duration(seconds: 10),
  );

  late FaceDetector _faceDetector;
  var detectedFaces = <Face>[].obs;
  CameraDescription? _currentCamera;

  img.Image? convertedImageTemp;
  Face? faceTemp;

  bool _isBusy = false;

  bool _shouldSkipFrame() {
    if (_isBusy || isProcessing.value) return true;
    if (DateTime.now().difference(_lastDetectionTime).inMilliseconds < 500) {
      return true;
    }
    return false;
  }

  Future<Face?> _detectFaceFromImage(CameraImage image) async {
    final inputImage = CameraUtils.convertCameraImageToInputImage(
      image,
      _currentCamera!,
    );
    if (inputImage == null) return null;

    final faces = await _faceDetector.processImage(inputImage);
    if (faces.isEmpty) return null;

    final face = faces.first;
    // L·ªçc khu√¥n m·∫∑t qu√° nh·ªè (r√°c)
    if (face.boundingBox.width < 80) return null;

    return face;
  }

  void _lockProcessing() {
    isProcessing.value = true;
    _lastDetectionTime = DateTime.now();
  }

  // Logic to√°n h·ªçc t√≠nh to√°n v√πng Crop (ƒë√£ t√°ch ra cho g·ªçn)
  Rect _calculateCropRect(Face face, int imgWidth, int imgHeight) {
    double centerX = face.boundingBox.center.dx;
    double centerY = face.boundingBox.center.dy;

    // Scale factor 0.5 (L·∫•y r·ªông ra 50%)
    double maxSide = max(face.boundingBox.width, face.boundingBox.height);
    double sideLength = maxSide * 1.5;

    double x = centerX - sideLength / 2;
    double y = centerY - sideLength / 2;

    // Boundary check (Gi·ªØ nguy√™n logic c·ªßa b·∫°n nh∆∞ng d√πng class Rect c·ªßa Dart)
    x = x < 0 ? 0 : x;
    y = y < 0 ? 0 : y;

    if (x + sideLength > imgWidth) sideLength = imgWidth - x;
    if (y + sideLength > imgHeight) sideLength = imgHeight - y;

    return Rect.fromLTWH(x, y, sideLength, sideLength);
  }

  Future<String?> _generateDebugPath() async {
    try {
      final dir = await getExternalStorageDirectory();
      if (dir != null) {
        // 1. ƒê·∫∑t t√™n file c·ªë ƒë·ªãnh
        final String path = '${dir.path}/debug_face.jpg';

        // 2. In ƒë∆∞·ªùng d·∫´n ra console ƒë·ªÉ debug
        debugPrint("üíæ File path: $path");

        return path;
      }
    } catch (e) {
      debugPrint("‚ö†Ô∏è L·ªói t·∫°o ƒë∆∞·ªùng d·∫´n: $e");
    }
    return null;
  }

  Future<void> _performRecognition(List<int> faceBytes) async {
    debugPrint("ü§ñ Isolate xong. Predict...");
    // 1. T√°i t·∫°o cv.Mat t·ª´ bytes nh·∫≠n ƒë∆∞·ª£c
    // K√≠ch th∆∞·ªõc c·ªë ƒë·ªãnh 112x112 (do Isolate ƒë√£ warpAffine v·ªÅ size n√†y)
    // Type l√† CV_8UC3 (3 k√™nh m√†u BGR)
    cv.Mat faceMat = cv.Mat.fromList(112, 112, cv.MatType.CV_8UC3, faceBytes);

    try {
      // 2. G·ªçi Service (L√∫c n√†y Service nh·∫≠n v√†o cv.Mat chu·∫©n ch·ªâ)
      final result = await _aiService.predict(faceMat);

      if (!result.isUnknown) {
        // ‚úÖ SUCCESS
        recognizedName.value = result.name;
        Get.snackbar(
          "Th√†nh c√¥ng",
          "Xin ch√†o ${result.name} (${result.distance.toStringAsFixed(2)})",
          backgroundColor: const Color(0xAA4CAF50),
          colorText: Colors.white,
          duration: const Duration(seconds: 1),
        );

        // cameraController?.stopImageStream();
        await Future.delayed(const Duration(seconds: 2));
        // SystemNavigator.pop(); // Ho·∫∑c navigate ƒëi ƒë√¢u ƒë√≥

        // üëâ QUAN TR·ªåNG: Reset l·∫°i t√™n ƒë·ªÉ UI bi·∫øt l√† ƒë√£ xong phi√™n n√†y
        recognizedName.value = "";

        // üëâ QUAN TR·ªåNG NH·∫§T: M·ªü kh√≥a ƒë·ªÉ x·ª≠ l√Ω frame ti·∫øp theo
        isProcessing.value = false;
      } else {
        // ‚ö†Ô∏è UNKNOWN
        recognizedName.value = "Unknown";
        debugPrint("‚ö†Ô∏è Ng∆∞·ªùi l·∫° (Dist: ${result.distance.toStringAsFixed(2)})");
        isProcessing.value = false;
      }
    } catch (e) {
      debugPrint("‚ùå L·ªói AI Predict: $e");
      isProcessing.value = false;
    } finally {
      // 3. Quan tr·ªçng: Gi·∫£i ph√≥ng b·ªô nh·ªõ Mat sau khi d√πng xong
      faceMat.dispose();
    }
  }

  void _safeguardUnlock() async {
    // Logic m·ªü kh√≥a an to√†n n·∫øu b·ªã k·∫πt
    if (isProcessing.value) {
      // Ch·ªâ delay nh·∫π ƒë·ªÉ tr√°nh spam UI n·∫øu v·ª´a fail xong
      await Future.delayed(const Duration(milliseconds: 500));
      // Check l·∫°i l·∫ßn n·ªØa xem ƒë√£ c√≥ ai m·ªü ch∆∞a, n·∫øu ch∆∞a th√¨ m·ªü
      if (recognizedName.value == "Unknown") {
        isProcessing.value = false;
      }
    }
  }

  @override
  void onInit() async {
    super.onInit();
    await _aiService.initialize();

    // 2. C·∫•u h√¨nh ML Kit
    _faceDetector = FaceDetector(
      options: FaceDetectorOptions(
        performanceMode: FaceDetectorMode.accurate, // ∆Øu ti√™n ƒë·ªô ch√≠nh x√°c
        enableContours: false,
        enableLandmarks: true,
        enableClassification: false,
        minFaceSize: 0.15,
      ),
    );

    startCamera(); // T·ª± ƒë·ªông ch·∫°y cam khi controller ƒë∆∞·ª£c t·∫°o
  }

  Future<void> startCamera() async {
    errorMsg.value = "";
    var status = await Permission.camera.request(); // Xin quy·ªÅn Camera
    if (!status.isGranted) {
      errorMsg.value = "Vui l√≤ng c·∫•p quy·ªÅn Camera";
      return;
    }

    final cameras = await availableCameras();
    if (cameras.isEmpty) {
      errorMsg.value = "Kh√¥ng t√¨m th·∫•y Camera";
      return;
    }

    _currentCamera = cameras.firstWhere(
      (c) => c.lensDirection == CameraLensDirection.front,
      orElse: () => cameras.first,
    ); // T√¨m Camera tr∆∞·ªõc

    // await _initializeController(_currentCamera!);
    cameraController = CameraController(
      _currentCamera!,
      ResolutionPreset.high, // ƒê·ª´ng d√πng High, d√πng Medium cho nh·∫π
      enableAudio: false,
      // T·ª± ƒë·ªông ch·ªçn format chu·∫©n theo OS
      imageFormatGroup: Platform.isAndroid
          ? ImageFormatGroup
                .nv21 // Android
          : ImageFormatGroup.bgra8888, // iOS
    );

    await cameraController!.initialize();
    isInitialized.value = true;

    // B·∫Øt ƒë·∫ßu Stream
    await cameraController!.startImageStream(
      _processFrame,
    ); // ·ªói khi camera b·∫Øt ƒë∆∞·ª£c 1 h√¨nh, n√≥ b·∫Øn ngay v√†o h√†m _processFrame
  }

  // --- LOGIC X·ª¨ L√ù FRAME ---
  void _processFrame(CameraImage image) async {
    // 1. Ki·ªÉm tra ƒëi·ªÅu ki·ªán ch·∫°y (Throttling & Busy state)
    if (_shouldSkipFrame()) return;

    _isBusy = true;

    try {
      // 2. Detect khu√¥n m·∫∑t (ML Kit)
      final Face? face = await _detectFaceFromImage(image);

      // N·∫øu kh√¥ng c√≥ m·∫∑t ho·∫∑c ƒëang x·ª≠ l√Ω frame kh√°c -> D·ª´ng
      if (face == null || isProcessing.value) return;

      // 3. Lock process ƒë·ªÉ b·∫Øt ƒë·∫ßu x·ª≠ l√Ω chuy√™n s√¢u
      _lockProcessing();

      // 4. Chu·∫©n b·ªã d·ªØ li·ªáu cho Isolate
      // L∆ØU √ù: Ch·ªâ clone bytes khi th·ª±c s·ª± c·∫ßn thi·∫øt (Ti·∫øt ki·ªám hi·ªáu nƒÉng)
      final rawBytes = _cloneCameraBytes(image);
      final debugPath = await _generateDebugPath();

      // T√≠nh to√°n v√πng crop
      final cropRect = _calculateCropRect(face, image.width, image.height);

      final request = FaceProcessRequest(
        yuvBytes: rawBytes,
        width: image.width,
        height: image.height,
        face: face, // ƒê√£ truy·ªÅn face chu·∫©n
        cropX: cropRect.left.toInt(),
        cropY: cropRect.top.toInt(),
        cropW: cropRect.width.toInt(),
        cropH: cropRect.height.toInt(),
        sensorOrientation: _currentCamera!.sensorOrientation,
        isAndroid: Platform.isAndroid,
        debugPath: debugPath,
        rootToken: RootIsolateToken.instance,
      );

      // 5. G·ª≠i sang Isolate (N·∫∑ng nh·∫•t)
      debugPrint("üöÄ G·ª≠i task sang Isolate...");
      final List<int>? alignedFaceBytes = await compute(
        isolateFaceProcessor,
        request,
      );

      // 6. Predict & Update UI
      if (alignedFaceBytes != null) {
        await _performRecognition(alignedFaceBytes);
      } else {
        // Isolate tr·∫£ v·ªÅ null (l·ªói x·ª≠ l√Ω ·∫£nh) -> Unlock ngay
        isProcessing.value = false;
      }
    } catch (e, s) {
      debugPrint("‚ùå L·ªói processFrame: $e");
      debugPrintStack(stackTrace: s);
      isProcessing.value = false; // M·ªü kh√≥a n·∫øu l·ªói
    } finally {
      _isBusy = false;
      _safeguardUnlock(); // ƒê·∫£m b·∫£o kh√¥ng b·ªã deadlock
    }
  }

  // H√†m h·ªó tr·ª£ Clone (Copy s√¢u) d·ªØ li·ªáu ·∫£nh
  Uint8List _cloneCameraBytes(CameraImage image) {
    final int width = image.width;
    final int height = image.height;

    // T√≠nh k√≠ch th∆∞·ªõc chu·∫©n NV21: Y (w*h) + UV (w*h/2)
    final int targetSize = width * height + ((width * height) ~/ 2);
    final buffer = Uint8List(targetSize);

    try {
      // TR∆Ø·ªúNG H·ª¢P 1: Camera tr·∫£ v·ªÅ ƒë√∫ng 3 Planes (Y, U, V) - Chu·∫©n Android
      if (image.planes.length == 3) {
        final yPlane = image.planes[0];
        // final uPlane = image.planes[1];
        final vPlane = image.planes[2];

        // 1. Copy Y (Lu√¥n ƒë√∫ng)
        buffer.setRange(0, width * height, yPlane.bytes);

        // 2. Copy UV
        // M·∫πo: Tr√™n Android, Plane V th∆∞·ªùng ch·ª©a c·∫£ U xen k·∫Ω (VUVU...)
        // Check pixelStride ƒë·ªÉ bi·∫øt n√≥ c√≥ xen k·∫Ω kh√¥ng
        if (vPlane.bytesPerPixel == 2) {
          // ƒê√¢y l√† d·∫°ng NV21 chu·∫©n, ta copy lu√¥n plane V v√†o ph·∫ßn sau c·ªßa buffer
          // L∆∞u √Ω: C++ c·ªßa b·∫°n ƒëang ƒë·ªçc UV xen k·∫Ω, n√™n c√°ch n√†y an to√†n nh·∫•t.
          int uvOffset = width * height;
          int bytesToCopy = vPlane.bytes.length;

          // Ch·ªâ copy n·∫øu ƒë·ªß ch·ªó, tr√°nh Crash
          if (uvOffset + bytesToCopy <= targetSize) {
            buffer.setRange(uvOffset, uvOffset + bytesToCopy, vPlane.bytes);
          } else {
            // N·∫øu buffer V qu√° l·ªõn, ch·ªâ l·∫•y ƒë√∫ng ph·∫ßn m√¨nh c·∫ßn
            buffer.setRange(
              uvOffset,
              targetSize,
              vPlane.bytes.sublist(0, targetSize - uvOffset),
            );
          }
        } else {
          // Tr∆∞·ªùng h·ª£p hi·∫øm: 3 plane r·ªùi r·∫°c (I420), ph·∫£i gh√©p tay (ch·∫≠m h∆°n x√≠u nh∆∞ng an to√†n)
          // Logic gh√©p tay ph·ª©c t·∫°p, nh∆∞ng t·∫°m th·ªùi c·ª© fill 0 v√†o UV ƒë·ªÉ kh√¥ng crash C++
          // (·∫¢nh s·∫Ω ƒëen tr·∫Øng nh∆∞ng app kh√¥ng ch·∫øt)
        }
      }
      // TR∆Ø·ªúNG H·ª¢P 2: Camera tr·∫£ v·ªÅ 1 Plane duy nh·∫•t (Th∆∞·ªùng l√† YUV g√≥i chung ho·∫∑c Raw)
      else if (image.planes.length == 1) {
        final plane = image.planes[0];
        final int rowStride = plane.bytesPerRow; // ƒê√ÇY L√Ä CH√åA KH√ìA
        // final int pixelStride = plane.bytesPerPixel ?? 1;

        // TH1: D·ªØ li·ªáu s·∫°ch (Stride == Width) -> Copy nhanh
        if (rowStride == width) {
          int copyLen = plane.bytes.length > targetSize
              ? targetSize
              : plane.bytes.length;
          buffer.setRange(0, copyLen, plane.bytes.sublist(0, copyLen));
        }
        // TH2: C√≥ Padding (Stride > Width) -> Ph·∫£i l·ªçc b·ªè r√°c
        else {
          // A. Copy v√πng Y (Luminance)
          // Duy·ªát qua t·ª´ng d√≤ng, ch·ªâ l·∫•y ƒë√∫ng 'width' bytes, b·ªè ph·∫ßn th·ª´a
          for (int row = 0; row < height; row++) {
            int srcPos = row * rowStride;
            int dstPos = row * width;

            // Copy 1 h√†ng
            buffer.setRange(
              dstPos,
              dstPos + width,
              plane.bytes.sublist(srcPos, srcPos + width),
            );
          }

          // B. Copy v√πng UV (Chrominance)
          // V√πng UV b·∫Øt ƒë·∫ßu ngay sau v√πng Y (t√≠nh theo stride g·ªëc)
          int uvSrcStart = height * rowStride;
          int uvDstStart = width * height;

          // V√πng UV c√≥ chi·ªÅu cao = height / 2
          for (int row = 0; row < height ~/ 2; row++) {
            int srcPos = uvSrcStart + (row * rowStride);
            int dstPos = uvDstStart + (row * width);

            // Ki·ªÉm tra bi√™n ƒë·ªÉ kh√¥ng crash n·∫øu buffer thi·∫øu
            if (srcPos + width <= plane.bytes.length &&
                dstPos + width <= buffer.length) {
              buffer.setRange(
                dstPos,
                dstPos + width,
                plane.bytes.sublist(srcPos, srcPos + width),
              );
            }
          }
        }
      }
    } catch (e) {
      debugPrint("‚ö†Ô∏è L·ªói copy bytes: $e");
      // Tr·∫£ v·ªÅ buffer r·ªóng ho·∫∑c ƒëen x√¨ c√≤n h∆°n l√† l√†m Crash app
      return Uint8List(targetSize);
    }

    return buffer;
  }

  // // 1. H√†m g·ªçi UI nh·∫≠p t√™n (Gi·ªØ nguy√™n c·ªßa b·∫°n)
  // Future<void> registerNewFace() async {
  //   final ImagePicker picker = ImagePicker();
  //   final XFile? image = await picker.pickImage(source: ImageSource.gallery);
  //   if (image == null) return;

  //   TextEditingController nameController = TextEditingController();
  //   await Get.defaultDialog(
  //     title: "Nh·∫≠p t√™n nh√¢n vi√™n",
  //     content: TextField(
  //       controller: nameController,
  //       decoration: const InputDecoration(hintText: "V√≠ d·ª•: Nguyen Van A"),
  //     ),
  //     textConfirm: "L∆∞u",
  //     textCancel: "H·ªßy",
  //     onConfirm: () async {
  //       String name = nameController.text.trim();
  //       if (name.isNotEmpty) {
  //         Get.back();
  //         // G·ªçi h√†m x·ª≠ l√Ω file t·ª´ Gallery
  //         await _processRegistrationGallery(File(image.path), name);
  //       }
  //     },
  //   );
  // }

  // // 2. H√†m x·ª≠ l√Ω file ·∫£nh t·ª´ Gallery
  // Future<void> _processRegistrationGallery(File file, String name) async {
  //   isProcessing.value = true;
  //   try {
  //     debugPrint("‚è≥ ƒêang t·∫°o vector t·ª´ ·∫£nh th∆∞ vi·ªán...");

  //     // L·∫•y vector t·ª´ file ·∫£nh
  //     List<double>? embedding = await _aiService.getEmbeddingFromImageFile(
  //       file,
  //     );

  //     if (embedding != null) {
  //       // L∆∞u vector v√†o DB v·ªõi t√™n ng∆∞·ªùi d√πng
  //       _aiService.registerUser(name, embedding);

  //       Get.snackbar(
  //         "Th√†nh c√¥ng",
  //         "ƒê√£ th√™m nh√¢n vi√™n: $name",
  //         backgroundColor: Colors.green,
  //       );
  //     } else {
  //       Get.snackbar(
  //         "L·ªói",
  //         "Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t h·ª£p l·ªá trong ·∫£nh",
  //         backgroundColor: Colors.red,
  //       );
  //     }
  //   } catch (e) {
  //     Get.snackbar("L·ªói", "C√≥ s·ª± c·ªë: $e");
  //   } finally {
  //     isProcessing.value = false;
  //   }
  // }

  // // (Optional) N·∫øu b·∫°n mu·ªën l√†m n√∫t "ƒêƒÉng k√Ω ng∆∞·ªùi ƒëang ƒë·ª©ng tr∆∞·ªõc Camera"
  // void registerCurrentFace(String name) {
  //   if (convertedImageTemp != null && faceTemp != null) {
  //     _aiService.registerFace(convertedImageTemp!, faceTemp!, name);
  //     Get.snackbar(
  //       "Th√†nh c√¥ng",
  //       "ƒê√£ l∆∞u nh√¢n vi√™n: $name",
  //       backgroundColor: Colors.green,
  //       colorText: Colors.white,
  //     );

  //     // Reset l·∫°i t√™n ƒë·ªÉ l·∫ßn qu√©t t·ªõi n√≥ hi·ªán t√™n m·ªõi lu√¥n
  //     recognizedName.value = name;
  //   } else {
  //     Get.snackbar("L·ªói", "Ch∆∞a nh·∫≠n di·ªán ƒë∆∞·ª£c m·∫∑t ƒë·ªÉ ƒëƒÉng k√Ω");
  //   }
  // }

  @override
  void onClose() {
    _faceDetector.close();
    cameraController?.stopImageStream();
    cameraController?.dispose();
    super.onClose();
  }
}
