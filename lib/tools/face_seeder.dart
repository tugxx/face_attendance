import 'dart:convert';
import 'dart:io';
import 'dart:typed_data';
import 'dart:math' as math;

import 'package:flutter/material.dart';
import 'package:flutter/services.dart';
import 'package:opencv_dart/opencv_dart.dart' as cv;
import 'package:google_mlkit_face_detection/google_mlkit_face_detection.dart';
import 'package:flutter_image_compress/flutter_image_compress.dart';
// import 'package:image/image.dart' as img;
import 'package:path_provider/path_provider.dart';
import 'package:http/http.dart' as http;
import 'package:archive/archive.dart';
import 'package:tflite_flutter/tflite_flutter.dart';

import '../app/core/services/face_aligner_cv.dart';

class ToolAIService {
  Interpreter? _interpreter;
  int _inputSize = 112;
  int _outputSize = 192;

  TensorType _inputType = TensorType.float32;

  // Tham s·ªë Quantization (D√†nh cho model int8/uint8)
  double _scale = 1.0;
  int _zeroPoint = 0;

  static const double normAlpha = 1.0 / 128.0;
  static const double normBeta = -127.5 / 128.0;

  int get inputSize => _inputSize;
  int get outputSize => _outputSize;

  static const String modelPath = 'assets/models/mobilefacenet.tflite';

  Future<void> initialize() async {
    try {
      // Load Interpreter v·ªõi options t·ªëi ∆∞u cho Android/iOS
      final options = InterpreterOptions();

      _interpreter = await Interpreter.fromAsset(modelPath, options: options);

      // 1. T·ª∞ ƒê·ªòNG L·∫§Y INPUT SHAPE
      var inputTensor = _interpreter!.getInputTensor(0);
      _inputSize = inputTensor.shape[1];
      _inputType = inputTensor.type;

      // L·∫•y tham s·ªë Quantization (N·∫øu model l√† float th√¨ scale=0, zeroPoint=0)
      if (inputTensor.params.scale > 0) {
        _scale = inputTensor.params.scale;
        _zeroPoint = inputTensor.params.zeroPoint;
      }

      var outputTensor = _interpreter!.getOutputTensor(0);
      _outputSize = outputTensor.shape[1];

      debugPrint("üß† AI Model Loaded: $modelPath");
      debugPrint("   - Input: ${_inputSize}x$_inputSize");
      debugPrint("   - Input Type: $_inputType");
      debugPrint("   - Quantization: Scale=$_scale, ZeroPoint=$_zeroPoint");
      debugPrint("   - Output Vector: $_outputSize dimensions");

      // // --- 3. WARMUP (T·ª± ƒë·ªông theo ki·ªÉu d·ªØ li·ªáu) ---
      // // T·∫°o buffer input gi·∫£ l·∫≠p
      // Object inputBuffer;
      // if (_inputType == TensorType.float32) {
      //   inputBuffer = Float32List(
      //     1 * _inputSize * _inputSize * 3,
      //   ).reshape([1, _inputSize, _inputSize, 3]);
      // } else if (_inputType == TensorType.int8) {
      //   inputBuffer = Int8List(
      //     1 * _inputSize * _inputSize * 3,
      //   ).reshape([1, _inputSize, _inputSize, 3]);
      // } else {
      //   // uint8
      //   inputBuffer = Uint8List(
      //     1 * _inputSize * _inputSize * 3,
      //   ).reshape([1, _inputSize, _inputSize, 3]);
      // }

      // var outputBuffer = List.filled(
      //   1 * _outputSize,
      //   0.0,
      // ).reshape([1, _outputSize]);

      var inputBuffer = Float32List(
        1 * _inputSize * _inputSize * 3,
      ).reshape([1, _inputSize, _inputSize, 3]);
      var outputBuffer = List.filled(
        _outputSize,
        0.0,
      ).reshape([1, _outputSize]);

      _interpreter?.run(inputBuffer, outputBuffer);

      debugPrint("üß† AI Tool Model loaded. Output: $_outputSize");
    } catch (e) {
      debugPrint("‚ùå Error loading Model: $e");
    }
  }

  // Logic Generate Embedding (GI·ªêNG H·ªÜT APP)
  List<double> generateEmbedding(cv.Mat alignedMat) {
    if (_interpreter == null) {
      debugPrint("‚ö†Ô∏è Model ch∆∞a init!");
      return [];
    }

    // // 1. Chu·∫©n h√≥a Input (Pre-processing)
    // // C√°c model InsightFace th∆∞·ªùng d√πng chu·∫©n: (pixel - 127.5) / 128.0
    // // Input ph·∫£i ƒë√∫ng k√≠ch th∆∞·ªõc model y√™u c·∫ßu (th∆∞·ªùng l√† 112x112)
    // if (image.width != _inputSize || image.height != _inputSize) {
    //   image = img.copyResize(image, width: _inputSize, height: _inputSize);
    // }

    // double imageMean = 127.5;
    // double imageStd = 128.0;

    // // Kh·ªüi t·∫°o m·∫£ng ph·∫≥ng (flat array) t√πy theo ki·ªÉu d·ªØ li·ªáu
    // List<num> flatInput;
    // if (_inputType == TensorType.float32) {
    //   flatInput = Float32List(1 * _inputSize * _inputSize * 3);
    // } else if (_inputType == TensorType.int8) {
    //   flatInput = Int8List(1 * _inputSize * _inputSize * 3);
    // } else {
    //   flatInput = Uint8List(1 * _inputSize * _inputSize * 3);
    // }

    // int pixelIndex = 0;
    // for (var i = 0; i < _inputSize; i++) {
    //   for (var j = 0; j < _inputSize; j++) {
    //     var pixel = image.getPixel(j, i);

    //     // B∆∞·ªõc A: T√≠nh gi√° tr·ªã Float chu·∫©n h√≥a tr∆∞·ªõc
    //     double r = (pixel.r.toDouble() - imageMean) / imageStd;
    //     double g = (pixel.g.toDouble() - imageMean) / imageStd;
    //     double b = (pixel.b.toDouble() - imageMean) / imageStd;

    //     // B∆∞·ªõc B: N·∫øu l√† model Quantized, chuy·ªÉn Float -> Int
    //     // C√¥ng th·ª©c: q = (f / scale) + zero_point
    //     if (_inputType != TensorType.float32) {
    //       flatInput[pixelIndex++] = (r / _scale + _zeroPoint).round().clamp(
    //         -128,
    //         255,
    //       );
    //       flatInput[pixelIndex++] = (g / _scale + _zeroPoint).round().clamp(
    //         -128,
    //         255,
    //       );
    //       flatInput[pixelIndex++] = (b / _scale + _zeroPoint).round().clamp(
    //         -128,
    //         255,
    //       );
    //     } else {
    //       // Model Float th∆∞·ªùng
    //       flatInput[pixelIndex++] = r;
    //       flatInput[pixelIndex++] = g;
    //       flatInput[pixelIndex++] = b;
    //     }
    //   }
    // }

    // // 3. Reshape ƒë·ªÉ ƒë∆∞a v√†o model [1, 112, 112, 3]
    // Object inputTensorData;
    // if (flatInput is Float32List) {
    //   inputTensorData = flatInput.reshape([1, _inputSize, _inputSize, 3]);
    // } else if (flatInput is Int8List) {
    //   inputTensorData = flatInput.reshape([1, _inputSize, _inputSize, 3]);
    // } else {
    //   inputTensorData = (flatInput as Uint8List).reshape([
    //     1,
    //     _inputSize,
    //     _inputSize,
    //     3,
    //   ]);
    // }

    // // 4. Chu·∫©n b·ªã Output
    // // L∆∞u √Ω: Ngay c·∫£ model Input Int8, th√¨ Output Embedding th∆∞·ªùng v·∫´n l√† Float32
    // // (tr·ª´ khi Full Integer Quantization). Ta c·ª© h·ª©ng b·∫±ng Float32, n·∫øu model tr·∫£ v·ªÅ Int8 th√¨ ta Dequantize sau.
    // var outputTensor = _interpreter!.getOutputTensor(0);
    // List<dynamic> outputBuffer; // D√πng dynamic ƒë·ªÉ linh ho·∫°t

    // if (outputTensor.type == TensorType.float32) {
    //   outputBuffer = List.filled(
    //     1 * _outputSize,
    //     0.0,
    //   ).reshape([1, _outputSize]);
    // } else {
    //   // Tr∆∞·ªùng h·ª£p output c≈©ng b·ªã quantized (hi·∫øm g·∫∑p v·ªõi Embedding nh∆∞ng c√≥ th·ªÉ)
    //   // Ta h·ª©ng t·∫°m b·∫±ng int, sau ƒë√≥ s·∫Ω convert ra float
    //   outputBuffer = List.filled(1 * _outputSize, 0).reshape([1, _outputSize]);
    // }

    try {
      // 1. Convert BGR -> RGB (B·∫ÆT BU·ªòC)
      // OpenCV m·∫∑c ƒë·ªãnh l√† BGR, Model AI c·∫ßn RGB
      cv.Mat rgbMat = cv.cvtColor(alignedMat, cv.COLOR_BGR2RGB);

      // 2. Resize ·∫£nh n·∫øu k√≠ch th∆∞·ªõc ·∫£nh ƒë·∫ßu v√†o kh√°c v·ªõi k√≠ch th∆∞·ªõc model y√™u c·∫ßu
      // (Ph√≤ng tr∆∞·ªùng h·ª£p ·∫£nh crop ra l√† 112x112 nh∆∞ng model l·∫°i c·∫ßn 128x128)
      if (rgbMat.rows != _inputSize || rgbMat.cols != _inputSize) {
        // debugPrint("‚ö†Ô∏è Resize ·∫£nh t·ª´ ${rgbMat.rows} -> $_inputSize");
        cv.Mat resizedMat = cv.resize(rgbMat, (
          _inputSize,
          _inputSize,
        ), interpolation: cv.INTER_LINEAR);
        rgbMat.dispose(); // Gi·∫£i ph√≥ng ·∫£nh c≈©
        rgbMat = resizedMat; // G√°n ·∫£nh m·ªõi
      }

      // 2. Convert sang Float32 & Normalize
      cv.Mat floatMat = rgbMat.convertTo(
        cv.MatType.CV_32FC3,
        alpha: normAlpha, // 1/128
        beta: normBeta, // -127.5/128
      );

      // 3. L·∫•y d·ªØ li·ªáu RAW HWC (Height-Width-Channel)
      // T·ª©c l√†: [R1, G1, B1, R2, G2, B2, ...]
      // ƒê√¢y l√† ƒë·ªãnh d·∫°ng native c·ªßa ·∫£nh v√† TFLite th√≠ch c√°i n√†y.
      final byteData = floatMat.data;

      // S·ª≠ d·ª•ng offsetInBytes ƒë·ªÉ AN TO√ÄN B·ªò NH·ªö (Tr√°nh crash SIGSEGV)
      final inputFloatList = Float32List.view(
        byteData.buffer,
        byteData.offsetInBytes,
        byteData.lengthInBytes ~/ 4,
      );

      // 4. ƒê∆∞a v√†o Model
      var inputBuffer = Float32List.fromList(inputFloatList).reshape([
        1,
        _inputSize,
        _inputSize,
        3, // S·ªë k√™nh m√†u (RGB) th∆∞·ªùng lu√¥n l√† 3
      ]);

      var outputBuffer = List.filled(
        _outputSize,
        0.0,
      ).reshape([1, _outputSize]);

      // 5. Run Inference
      _interpreter!.run(inputBuffer, outputBuffer);

      // // 6. X·ª≠ l√Ω k·∫øt qu·∫£ (Dequantize Output n·∫øu c·∫ßn)
      // List<double> rawEmbedding = [];
      // var rawOutput = outputBuffer[0]; // L·∫•y batch ƒë·∫ßu ti√™n

      // if (outputTensor.type == TensorType.float32) {
      //   rawEmbedding = List<double>.from(rawOutput);
      // } else {
      //   // N·∫øu Output l√† Int8, ta c·∫ßn ƒë·ªïi ng∆∞·ª£c l·∫°i ra Float ƒë·ªÉ t√≠nh to√°n kho·∫£ng c√°ch
      //   // C√¥ng th·ª©c: f = (q - zero_point) * scale
      //   double outScale = outputTensor.params.scale;
      //   int outZeroPoint = outputTensor.params.zeroPoint;
      //   for (var val in rawOutput) {
      //     rawEmbedding.add((val - outZeroPoint) * outScale);
      //   }
      // }

      // D·ªçn d·∫πp
      rgbMat.dispose();
      floatMat.dispose();

      // 6. L·∫•y k·∫øt qu·∫£ & L2 Normalize
      List<double> rawEmbedding = List<double>.from(outputBuffer[0]);
      return _l2Normalize(rawEmbedding);
    } catch (e) {
      debugPrint("‚ùå Error generating embedding: $e");
      return [];
    }
  }

  List<double> _l2Normalize(List<double> embedding) {
    double squareSum = 0;
    for (var x in embedding) {
      squareSum += x * x;
    }
    double xInvNorm = math.sqrt(math.max(squareSum, 1e-10));
    return embedding.map((x) => x / xInvNorm).toList();
  }

  void dispose() {
    _interpreter?.close();
  }
}

class FaceSeeder extends StatefulWidget {
  const FaceSeeder({super.key});

  @override
  State<FaceSeeder> createState() => _FaceSeederState();
}

class _FaceSeederState extends State<FaceSeeder> {
  String _status = "S·∫µn s√†ng...";
  bool _isProcessing = false;
  final ToolAIService _aiService = ToolAIService();
  late FaceDetector _faceDetector;

  Map<String, List<List<double>>> tempMapEmbeddings = {};
  final Map<String, int> _debugImageCounter = {};

  @override
  void initState() {
    super.initState();
    // Kh·ªüi t·∫°o ML Kit
    _faceDetector = FaceDetector(
      options: FaceDetectorOptions(
        performanceMode: FaceDetectorMode.accurate,
        enableLandmarks: true,
        enableContours: false,
      ),
    );
    // Kh·ªüi t·∫°o AI Service (Load model TFLite)
    _aiService.initialize();
  }

  // --- H√ÄM CH√çNH: X·ª¨ L√ù V√Ä XU·∫§T JSON ---
  Future<void> _startSeeding() async {
    setState(() {
      _isProcessing = true;
      _status = "ƒêang gi·∫£i n√©n & X·ª≠ l√Ω...";
    });

    _debugImageCounter.clear();
    tempMapEmbeddings.clear();

    // B·∫Øt ƒë·∫ßu b·∫•m gi·ªù
    Stopwatch stopwatch = Stopwatch()..start();
    int totalImagesProcessed = 0;

    try {
      final extDir = await getExternalStorageDirectory();
      final debugDir = Directory('${extDir!.path}/debug_seeder');
      if (await debugDir.exists()) {
        await debugDir.delete(recursive: true);
      }
    } catch (_) {}

    try {
      // 1. ƒê·ªçc file Zip t·ª´ Assets
      final byteData = await rootBundle.load('assets/dataset.zip');
      final buffer = byteData.buffer.asUint8List();

      // 2. Gi·∫£i n√©n
      final archive = ZipDecoder().decodeBytes(buffer);

      debugPrint("üì¶ ƒê√£ t√¨m th·∫•y ${archive.length} file trong Zip.");

      // 3. Duy·ªát t·ª´ng file trong file Zip
      for (final file in archive) {
        if (file.isFile) {
          final filename = file.name; // V√≠ d·ª•: dataset/xuantung/anh1.jpg

          // L·ªçc ch·ªâ l·∫•y ·∫£nh
          if (!filename.toLowerCase().endsWith('.jpg') &&
              !filename.toLowerCase().endsWith('.png') &&
              !filename.toLowerCase().endsWith('.jpeg')) {
            continue;
          }

          totalImagesProcessed++;

          // Ph√¢n t√≠ch t√™n User t·ª´ ƒë∆∞·ªùng d·∫´n trong Zip
          // dataset/xuantung/anh1.jpg -> parts[-2] l√† xuantung
          List<String> parts = filename.split('/');
          if (parts.length < 2) continue;

          // N·∫øu c·∫•u tr√∫c l√† dataset/xuantung/anh.jpg th√¨ l·∫•y parts[parts.length - 2]
          // N·∫øu zip tr·ª±c ti·∫øp xuantung/anh.jpg th√¨ l·∫•y parts[0]
          // Logic an to√†n: L·∫•y t√™n th∆∞ m·ª•c ch·ª©a file
          String name = parts[parts.length - 2];

          debugPrint("‚ö° ƒêang x·ª≠ l√Ω: $name - ${filename.split('/').last}");

          // A. Ghi file ra b·ªô nh·ªõ t·∫°m (Cache) ƒë·ªÉ ML Kit ƒë·ªçc
          final tempDir = await getTemporaryDirectory();
          final tempFile = File('${tempDir.path}/temp_img');
          await tempFile.writeAsBytes(file.content as List<int>);

          // B. X·ª≠ l√Ω ·∫£nh
          await _processImageFile(tempFile, name);

          // X√≥a file t·∫°m
          if (await tempFile.exists()) await tempFile.delete();

          final files = archive.files;
          final index = files.indexOf(file);

          setState(() {
            _status = "ƒêang x·ª≠ l√Ω: $name (${index + 1}/${files.length})";
          });
        }
      }

      Map<String, List<double>> finalJsonData = {};
      tempMapEmbeddings.forEach((user, embeddingsList) {
        if (embeddingsList.isNotEmpty) {
          finalJsonData[user] = _calculateMean(embeddingsList);
        }
      });

      debugPrint("‚úÖ ƒê√£ x·ª≠ l√Ω xong ${finalJsonData.length} ng∆∞·ªùi d√πng!");

      // --- SAU KHI X·ª¨ L√ù XONG T·∫§T C·∫¢ ·∫¢NH ---
      stopwatch.stop();

      // 1. L·∫•y th√¥ng s·ªë ch·∫•t l∆∞·ª£ng (H√†m v·ª´a s·ª≠a ·ªü tr√™n)
      var qualityStats = _validateDataQuality();

      // 2. L·∫•y th√¥ng s·ªë hi·ªáu nƒÉng
      int totalTimeMs = stopwatch.elapsedMilliseconds;
      double avgTimePerImage = totalImagesProcessed > 0
          ? totalTimeMs / totalImagesProcessed
          : 0.0;

      // 3. L·∫•y th√¥ng tin Model (Size, T√™n)
      String modelName = ToolAIService.modelPath.split('/').last;
      double modelSizeMB = 0.0;
      try {
        final byteData = await rootBundle.load(ToolAIService.modelPath);
        modelSizeMB = byteData.lengthInBytes / (1024 * 1024);
      } catch (e) {
        debugPrint("Kh√¥ng l·∫•y ƒë∆∞·ª£c size model: $e");
      }

      // 4. T·∫†O JSON B√ÅO C√ÅO (C√°i b·∫°n c·∫ßn ƒë√¢y)
      Map<String, dynamic> reportData = {
        "model_info": {
          "name": modelName,
          "input_size": _aiService.inputSize,
          "output_dim": _aiService.outputSize,
          "file_size_mb": double.parse(modelSizeMB.toStringAsFixed(2)),
          // N·∫øu d√πng code fix tr∆∞·ªõc ƒë√≥ th√¨ l·∫•y _aiService._inputType
          // "data_type": _aiService._inputType.toString(),
        },
        "performance": {
          "total_images": totalImagesProcessed,
          "total_time_ms": totalTimeMs,
          "avg_ms_per_image": double.parse(avgTimePerImage.toStringAsFixed(1)),
        },
        "quality_metrics": {
          // üëâ S·ª¨A ·ªû ƒê√ÇY: Key m·ªõi l√† 'intra_sim' (Cosine)
          "avg_intra_sim": double.parse(
            (qualityStats['intra_sim'] ?? 0.0).toStringAsFixed(4),
          ),
          // üëâ S·ª¨A ·ªû ƒê√ÇY: Key m·ªõi l√† 'inter_sim' (Cosine)
          "avg_inter_sim": double.parse(
            (qualityStats['inter_sim'] ?? 0.0).toStringAsFixed(4),
          ),
          // üëâ S·ª¨A ·ªû ƒê√ÇY: Margin = Intra - Inter
          "quality_margin": double.parse(
            (qualityStats['quality_score'] ?? 0.0).toStringAsFixed(4),
          ),
        },
        // K√®m lu√¥n d·ªØ li·ªáu vector ƒë·ªÉ backup
        // "database": finalJsonData
      };

      String reportJson = jsonEncode(reportData);
      String safeModelName = modelName.replaceAll('.', '_'); // w600k_r50_tflite

      // 5. G·ª≠i File B√°o C√°o
      String reportFileName = "report_$safeModelName.json";
      await _sendToServer(reportJson, filename: reportFileName);

      // 6. G·ª≠i File Database (Vector)
      String dbJsonString = json.encode(finalJsonData);
      String dbFileName = "db_$safeModelName.json";
      await _sendToServer(dbJsonString, filename: dbFileName);
    } catch (e) {
      debugPrint("‚ùå L·ªói: $e");
    } finally {
      setState(() {
        _isProcessing = false;
      });
    }
  }

  // void _log(String msg) {
  //   setState(() {
  //     _status = msg;
  //   });
  //   debugPrint(msg);
  // }

  Future<void> _processImageFile(File tempFile, String name) async {
    String? smallPath;

    try {
      final Uint8List? compressedBytes =
          await FlutterImageCompress.compressWithFile(
            tempFile.path,
            minWidth: 1280,
            minHeight: 1280,
            quality: 95,
            format: CompressFormat.jpeg,
          );

      if (compressedBytes == null) return;

      final tempDir = await getTemporaryDirectory();
      smallPath =
          '${tempDir.path}/temp_small_${DateTime.now().microsecondsSinceEpoch}.jpg';
      final smallFile = File(smallPath);
      await smallFile.writeAsBytes(compressedBytes);

      final inputImageFile = InputImage.fromFile(smallFile);
      final faces = await _faceDetector.processImage(inputImageFile);

      if (faces.isNotEmpty) {
        Face mainFace = faces.reduce((curr, next) {
          final currArea = curr.boundingBox.width * curr.boundingBox.height;
          final nextArea = next.boundingBox.width * next.boundingBox.height;
          return currArea > nextArea ? curr : next;
        });

        // Ki·ªÉm tra ph·ª• (Optional): N·∫øu khu√¥n m·∫∑t l·ªõn nh·∫•t v·∫´n qu√° nh·ªè so v·ªõi ·∫£nh th√¨ c√≥ th·ªÉ b·ªè qua
        // V√≠ d·ª•: Ch·ªâ nh·∫≠n n·∫øu m·∫∑t chi·∫øm > 10% di·ªán t√≠ch ·∫£nh (t√πy ch·ªânh n·∫øu c·∫ßn)
        // double imageArea = processingImage.width * processingImage.height * 1.0;
        // double faceArea = mainFace.boundingBox.width * mainFace.boundingBox.height;
        // if (faceArea / imageArea < 0.1) return;

        // final Uint8List? alignedBytes = await FaceAlignerCV.alignFace(
        //   smallFile.path,
        //   mainFace,
        //   targetSize: _aiService.inputSize,
        // );

        cv.Mat? alignedMat = await FaceAlignerCV.alignFace(
          smallFile.path,
          mainFace,
          debugName: name, // Truy·ªÅn t√™n ƒë·ªÉ l∆∞u ·∫£nh debug
          saveDebug: true, // üü¢ B·∫¨T C√ÅI N√ÄY L√äN
        );

        // -----------------------------------------------------------
        // 2. DEBUG: L∆ØU ·∫¢NH CROP RA FILE ƒê·ªÇ KI·ªÇM TRA
        // -----------------------------------------------------------
        if (alignedMat != null && !alignedMat.isEmpty) {
          // try {
          //   final extDir = await getExternalStorageDirectory();
          //   if (extDir != null) {
          //     // T·∫°o folder ri√™ng t√™n l√† 'debug_seeder' cho g·ªçn
          //     final debugDir = Directory('${extDir.path}/debug_seeder');
          //     if (!await debugDir.exists()) {
          //       await debugDir.create(recursive: true);
          //     }

          //     int count = (_debugImageCounter[name] ?? 0) + 1;
          //     _debugImageCounter[name] = count;

          //     final String debugPath = '${debugDir.path}/${name}_$count.jpg';

          //     File(debugPath).writeAsBytesSync(alignedBytes);

          //     debugPrint(
          //       "üì∏ [Debug] ƒê√£ l∆∞u crop c·ªßa $name t·∫°i: .../debug_seeder/",
          //     );
          //   }
          // } catch (e) {
          //   debugPrint("‚ö†Ô∏è L·ªói l∆∞u debug: $e");
          // }

          // img.Image? imgForAi = img.decodeImage(alignedBytes);

          // if (imgForAi != null) {
          //   // L·∫•y Vector
          //   List<double> emb = _aiService.generateEmbedding(imgForAi);

          //   // L∆∞u v√†o map t·∫°m
          //   if (!tempMapEmbeddings.containsKey(name)) {
          //     tempMapEmbeddings[name] = [];
          //   }
          //   tempMapEmbeddings[name]!.add(emb);
          // }

          // 2. T·∫°o embedding b·∫±ng h√†m HWC chu·∫©n
          List<double> emb = _aiService.generateEmbedding(alignedMat);

          // 3. L∆∞u
          if (!tempMapEmbeddings.containsKey(name)) {
            tempMapEmbeddings[name] = [];
          }
          tempMapEmbeddings[name]!.add(emb);

          alignedMat.dispose();
        }
      }
    } catch (e) {
      debugPrint("‚ö†Ô∏è L·ªói x·ª≠ l√Ω ·∫£nh: $e");
    } finally {
      // D·ªçn d·∫πp b·ªô nh·ªõ ngay l·∫≠p t·ª©c
      if (smallPath != null) {
        try {
          await File(smallPath).delete();
        } catch (_) {}
      }
      // Ngh·ªâ 50ms ƒë·ªÉ Garbage Collector k·ªãp d·ªçn RAM tr∆∞·ªõc khi qua ·∫£nh ti·∫øp theo
      // ƒê√¢y l√† b√≠ quy·∫øt ƒë·ªÉ kh√¥ng b·ªã OOM khi ch·∫°y v√≤ng l·∫∑p l·ªõn
      await Future.delayed(const Duration(milliseconds: 50));
    }
  }

  Map<String, double> _validateDataQuality() {
    debugPrint("\n--- üïµÔ∏è B·∫ÆT ƒê·∫¶U KI·ªÇM TRA CH·∫§T L∆Ø·ª¢NG D·ªÆ LI·ªÜU ---");

    double totalIntraSim = 0;
    int intraCount = 0;

    // 1. KI·ªÇM TRA ƒê·ªò ·ªîN ƒê·ªäNH (C√πng 1 ng∆∞·ªùi, c√°c ·∫£nh c√≥ gi·ªëng nhau kh√¥ng?)
    tempMapEmbeddings.forEach((name, embeddings) {
      if (embeddings.length < 2) {
        debugPrint("‚ö†Ô∏è $name: Ch·ªâ c√≥ 1 ·∫£nh -> Kh√¥ng th·ªÉ ki·ªÉm tra ƒë·ªô ·ªïn ƒë·ªãnh.");
        return;
      }

      double currentPersonSim = 0;
      int count = 0;

      // So s√°nh t·ª´ng c·∫∑p ·∫£nh c·ªßa c√πng 1 ng∆∞·ªùi
      for (int i = 0; i < embeddings.length - 1; i++) {
        for (int j = i + 1; j < embeddings.length; j++) {
          double sim = _cosineSimilarity(embeddings[i], embeddings[j]);
          currentPersonSim += sim;
          count++;
        }
      }

      double avgSim = currentPersonSim / count;
      totalIntraSim += avgSim;
      intraCount++;

      // ƒê√ÅNH GI√Å (Thang ƒëi·ªÉm Cosine):
      // > 0.8: Tuy·ªát v·ªùi (R·∫•t gi·ªëng nhau)
      // 0.6 - 0.8: ·ªîn
      // < 0.6: C·∫£nh b√°o (·∫¢nh c√πng 1 ng∆∞·ªùi m√† nh√¨n kh√°c nhau qu√°)
      String quality = avgSim > 0.8
          ? "‚úÖ T·ªët"
          : (avgSim > 0.6 ? "‚ö†Ô∏è T·∫°m" : "‚ùå KH√îNG ·ªîN ƒê·ªäNH");
      debugPrint(
        "üë§ $name ($count c·∫∑p ·∫£nh): Trung b√¨nh sai s·ªë = ${avgSim.toStringAsFixed(3)} -> $quality",
      );
    });

    double avgIntra = intraCount > 0 ? totalIntraSim / intraCount : 0.0;

    if (intraCount > 0) {
      debugPrint(
        "=> Sai s·ªë n·ªôi b·ªô trung b√¨nh to√†n data: ${avgIntra.toStringAsFixed(3)}",
      );
    }

    // 2. KI·ªÇM TRA ƒê·ªò PH√ÇN BI·ªÜT (Ng∆∞·ªùi A c√≥ kh√°c ng∆∞·ªùi B kh√¥ng?)
    debugPrint("\n--- ‚öîÔ∏è KI·ªÇM TRA PH√ÇN BI·ªÜT GI·ªÆA C√ÅC NG∆Ø·ªúI D√ôNG ---");
    List<String> names = tempMapEmbeddings.keys.toList();

    // T√≠nh vector trung b√¨nh t·∫°m th·ªùi ƒë·ªÉ so s√°nh
    Map<String, List<double>> means = {};
    tempMapEmbeddings.forEach((k, v) => means[k] = _calculateMean(v));

    double totalInterSim = 0;
    int interCount = 0;

    for (int i = 0; i < names.length - 1; i++) {
      for (int j = i + 1; j < names.length; j++) {
        String u1 = names[i];
        String u2 = names[j];
        double sim = _cosineSimilarity(means[u1]!, means[u2]!);

        totalInterSim += sim;
        interCount++;

        String statusIcon;
        String note = "";

        // ƒê√ÅNH GI√Å (Thang ƒëi·ªÉm Cosine):
        // > 0.6: NGUY HI·ªÇM (Hai ng∆∞·ªùi l·∫° m√† gi·ªëng nhau > 60%)
        // 0.4 - 0.6: H∆°i gi·ªëng
        // < 0.4: T·ªët (Kh√°c bi·ªát r√µ r√†ng)
        if (sim > 0.6) {
          statusIcon = "‚ùå NGUY HI·ªÇM";
          note = "(D·ªÖ nh·∫≠n nh·∫ßm)";
        } else if (sim > 0.4) {
          statusIcon = "‚ö†Ô∏è H∆°i gi·ªëng";
          note = "(C·∫©n th·∫≠n)";
        } else {
          statusIcon = "‚úÖ T·ªët";
        }

        // IN RA T·∫§T C·∫¢ C√ÅC C·∫∂P (Theo y√™u c·∫ßu c·ªßa b·∫°n)
        debugPrint(
          "$statusIcon $u1 vs $u2: Sim = ${sim.toStringAsFixed(3)} $note",
        );
      }
    }

    double avgInter = interCount > 0 ? totalInterSim / interCount : 0.0;

    // --- PH·∫¶N B·ªî SUNG ƒê·ªÇ H·∫æT L·ªñI V√Ä B√ÅO C√ÅO T·ªîNG QUAN ---
    if (interCount > 0) {
      debugPrint("--------------------------------------------------");
      debugPrint(
        "=> Kho·∫£ng c√°ch t√°ch bi·ªát trung b√¨nh: ${avgInter.toStringAsFixed(3)}",
      );

      // Margin = (Gi·ªëng n·ªôi b·ªô) - (Gi·ªëng ch√©o). C√†ng l·ªõn c√†ng t·ªët.
      double margin = avgIntra - avgInter;

      if (margin > 0.4) {
        debugPrint(
          "üåü T·ªîNG K·∫æT: Model ph√¢n bi·ªát R·∫§T T·ªêT! (Margin: ${margin.toStringAsFixed(2)})",
        );
      } else if (margin > 0.2) {
        debugPrint("‚úÖ T·ªîNG K·∫æT: Model ho·∫°t ƒë·ªông ·ªîN.");
      } else {
        debugPrint("‚ö†Ô∏è T·ªîNG K·∫æT: C·∫£nh b√°o, d·ªØ li·ªáu kh√≥ ph√¢n bi·ªát.");
      }
    }
    debugPrint("--------------------------------------------------\n");

    return {
      "intra_sim": avgIntra,
      "inter_sim": avgInter,
      "quality_score": avgIntra - avgInter, // ƒêi·ªÉm ch·∫•t l∆∞·ª£ng
    };
  }

  // --- H√ÄM T√çNH COSINE SIMILARITY (Thay th·∫ø Euclidean) ---
  // C√¥ng th·ª©c: A . B (V√¨ vector ƒë√£ ƒë∆∞·ª£c normalize ƒë·ªô d√†i = 1)
  double _cosineSimilarity(List<double> v1, List<double> v2) {
    double dot = 0.0;
    for (int i = 0; i < v1.length; i++) {
      dot += v1[i] * v2[i];
    }
    return dot;
  }

  // // Copy l·∫°i h√†m t√≠nh kho·∫£ng c√°ch v√†o ƒë√¢y n·∫øu ch∆∞a c√≥
  // double _euclideanDistance(List<double> v1, List<double> v2) {
  //   double sum = 0;
  //   for (int i = 0; i < v1.length; i++) {
  //     sum += math.pow((v1[i] - v2[i]), 2);
  //   }
  //   return math.sqrt(sum);
  // }

  // H√†m g·ª≠i JSON v·ªÅ Server Dart tr√™n PC
  Future<void> _sendToServer(
    String jsonString, {
    String filename = "face_db.json",
  }) async {
    debugPrint("üì° ƒêang g·ª≠i d·ªØ li·ªáu v·ªÅ m√°y t√≠nh...");
    try {
      // S·ª¨A IP T·∫†I ƒê√ÇY (D√πng ipconfig tr√™n PC ƒë·ªÉ xem)
      String serverUrl = "http://192.168.0.186:5000/upload-json";

      var response = await http.post(
        Uri.parse(serverUrl),
        headers: {"Content-Type": "application/json"},
        body: jsonEncode({
          "filename": filename, // G·ª≠i t√™n file l√™n server
          "content": jsonString,
        }),
      );

      if (response.statusCode == 200) {
        debugPrint(
          "üéâ TH√ÄNH C√îNG! File face_db.json ƒë√£ n·∫±m trong assets m√°y t√≠nh.",
        );
      } else {
        debugPrint("‚ö†Ô∏è Server l·ªói: ${response.statusCode}");
      }
    } catch (e) {
      debugPrint("‚ùå Kh√¥ng k·∫øt n·ªëi ƒë∆∞·ª£c: $e");
      debugPrint(
        "üëâ Ki·ªÉm tra l·∫°i IP m√°y t√≠nh v√† ƒë·∫£m b·∫£o Server Dart ƒëang ch·∫°y.",
      );
    }
  }

  // H√†m ph·ª•: T√≠nh trung b√¨nh
  List<double> _calculateMean(List<List<double>> embeddings) {
    int dim = embeddings[0].length;
    List<double> mean = List.filled(dim, 0.0);
    for (var emb in embeddings) {
      for (int i = 0; i < dim; i++) {
        mean[i] += emb[i];
      }
    }
    for (int i = 0; i < dim; i++) {
      mean[i] /= embeddings.length;
    }
    return mean;
  }

  // // H√†m ph·ª•: Asset -> File
  // Future<File> _assetToFile(String assetPath) async {
  //   final byteData = await rootBundle.load(assetPath);
  //   final tempDir = await getTemporaryDirectory();
  //   final tempFile = File('${tempDir.path}/${assetPath.split('/').last}');
  //   await tempFile.writeAsBytes(byteData.buffer.asUint8List());
  //   return tempFile;
  // }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      appBar: AppBar(title: const Text("C√¥ng c·ª• t·∫°o d·ªØ li·ªáu FaceDB")),
      body: Center(
        child: Column(
          mainAxisAlignment: MainAxisAlignment.center,
          children: [
            if (_isProcessing) const CircularProgressIndicator(),
            const SizedBox(height: 20),
            Text(
              _status,
              textAlign: TextAlign.center,
              style: const TextStyle(fontSize: 16),
            ),
            const SizedBox(height: 40),
            ElevatedButton.icon(
              onPressed: _isProcessing ? null : _startSeeding,
              icon: const Icon(Icons.engineering),
              label: const Text("B·∫Øt ƒë·∫ßu x·ª≠ l√Ω & Xu·∫•t JSON"),
              style: ElevatedButton.styleFrom(
                padding: const EdgeInsets.all(20),
              ),
            ),
          ],
        ),
      ),
    );
  }
}
